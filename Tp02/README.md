
#  شرح للأستاذ حول مشروع "التعامل مع ملفات Big Data في Python باستخدام Kaggle"

## مقدمة
هذا التقرير يوضح العمل المنجز داخل ملف **big_data.ipynb**، وهو يهدف إلى **استكشاف طرق فعالة للتعامل مع ملفات البيانات الكبيرة (5GB+) في بيئة محدودة الموارد (RAM = 2.7 GB)**.  
تم تنفيذ التجربة باستخدام بيانات تم تحميلها من منصة **Kaggle** عبر **API Token**.

---

## الأدوات والتقنيات المستخدمة
### 1. Kaggle API (باستخدام توكن)
تم إعداد `kaggle.json` الذي يحتوي على **توكن الحساب الشخصي** لتحميل البيانات مباشرة من Kaggle باستخدام الأوامر البرمجية.  
يسمح ذلك بتجاوز القيود اليدوية على التحميل ويسهّل تكرار التجربة.

### 2. Python Libraries
- **pandas**: لمعالجة البيانات التقليدية.  
- **dask**: لمعالجة البيانات الكبيرة بطريقة موازية (parallel processing).  
- **gzip** أو **compression tools**: لاختبار القراءة من ملفات مضغوطة لتقليل حجم I/O.  
- **time**, **psutil**: لقياس الزمن والذاكرة أثناء تنفيذ كل طريقة.

---

## هدف التجربة
اختبار **ثلاث طرق مختلفة لقراءة ومعالجة ملف CSV كبير** ومقارنة أدائها من حيث:
- وقت التنفيذ (Execution Time)  
- استهلاك الذاكرة (Memory Usage)  
- كفاءة المعالجة بالنسبة لحجم البيانات

---

## الطرق التي تم اختبارها داخل الملف
### الطريقة 1: `pandas.read_csv` مع `chunksize`
تمت قراءة البيانات على دفعات صغيرة (chunks) بحجم 100,000 صف تقريبًا.  
الهدف هو تقليل استهلاك الذاكرة عبر تحميل جزء من الملف فقط في كل دورة.

**النتائج الفعلية:**  
عدد الصفوف الكلي: **42,448,764 صفًا**  
الوقت المستغرق: **78.25 ثانية**  

**الميزة:** تعمل حتى في بيئة RAM محدودة.  
**العيب:** أبطأ لأن المعالجة تكون مجزأة ومتكررة.

---

### الطريقة 2: مكتبة Dask
تعمل بنفس واجهة `pandas` ولكنها تقسم الملف إلى أجزاء متعددة وتنفذ العمليات بشكل متوازي.  
تم اختبار عمليات مثل `groupby()` و `mean()` باستخدام Dask.

**الميزة:** أداء أسرع وفعالية أكبر مع الأنوية المتعددة (multi-core).  
**العيب:** يتطلب إعدادًا إضافيًا ويستهلك وقتًا عند أول تشغيل.

---

### الطريقة 3: القراءة من ملف مضغوط `.gz`
تمت قراءة نفس الملف بعد ضغطه بصيغة gzip لتقليل مساحة التخزين على القرص.  
الفكرة هي موازنة تقليل استخدام القرص مقابل زيادة وقت المعالجة قليلاً (بسبب فك الضغط).

**الميزة:** يقلل حجم الملفات ويحافظ على مساحة القرص.  
**العيب:** قد يزيد وقت CPU المستهلك.

---

## نتائج المقارنة (ملخص)
تم تسجيل القيم التجريبية في جدول ضمن التقرير السابق (README).  
إليك ملخصًا محدثًا للنتائج التقريبية:

| الطريقة | وقت التنفيذ (ث) | الذاكرة القصوى (GB RAM) | ملاحظات |
|---|---:|---:|---|
| pandas (chunksize=100k) | **78.25** | ~2.1 | مناسب للأجهزة الضعيفة، لكنه أبطأ قليلًا من Dask |
| Dask | 52.98 | ~1.8 | أسرع بفضل المعالجة الموازية |
| gzip (compression) | 137.87 | ~2.0 | مفيد لتقليل حجم الملفات على القرص |

---

## الخلاصة
- الطريقة باستخدام **pandas + chunksize** أعطت نتائج ممتازة: تم تحليل أكثر من **42 مليون صف** في **78 ثانية** فقط باستخدام 2.7GB RAM.  
- **Dask** أعطى أداءً أفضل في السرعة العامة، خصوصًا في العمليات الإحصائية المتعددة.  
- **Compression** مفيد في تقليل التخزين، لكنه يضيف عبئًا إضافيًا على CPU.

---

## النقاط التي تم توثيقها داخل الـ IPYNB
1. إعداد Kaggle token وتحميل البيانات أو استيرادها.  
2. تنفيذ كل طريقة مع قياس الوقت والذاكرة.  
3. عرض النتائج في جدول ومقارنتها.  
4. كتابة الملاحظات النهائية وتفسير النتائج.

---

## مقترحات للتحسين المستقبلي
- تجربة مكتبات أحدث مثل **Polars** أو **Vaex**.  
- اختبار على أحجام بيانات أكبر (10GB، 20GB).  
- مقارنة الأداء عند استخدام **GPU acceleration**.  
- توسيع التحليل ليشمل أداء القرص (Disk I/O).  

---

**اسم الطالب:** الأخوص علي 
**التخصص:** الذكاء الاصطناعي وعلوم البيانات  
**الجامعة:** جامعة الشهيد حمة لخضر الوادي  
**السنة:** ماستر 2  
**المشروع:** التعامل مع بيانات كبيرة باستخدام أدوات Python وKaggle

